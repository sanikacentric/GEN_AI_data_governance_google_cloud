{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Encryption: CMEK integration with BigQuery and Cloud Storage\n",
        "\n",
        "PII Detection & Masking: Cloud DLP integration for sensitive data handling\n",
        "\n",
        "Content Safety: Guardrails for prompt safety and content filtering\n",
        "\n",
        "Audit Logging: Cloud Logging integration for governance events\n",
        "\n",
        "Access Controls: IAM policy simulation for least privilege access\n",
        "\n",
        "Data Retention: Policy enforcement for compliance requirements\n",
        "\n",
        "Data Residency: Location enforcement for regulatory compliance"
      ],
      "metadata": {
        "id": "nF6SA8LXJCpb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFP0D-2gI8Ux"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Google Cloud Data Governance for GenAI Solutions\n",
        "Complete implementation with actual GCP integrations and simulations\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from enum import Enum\n",
        "import hashlib\n",
        "import base64\n",
        "\n",
        "# Google Cloud client libraries (would need to be installed)\n",
        "try:\n",
        "    from google.cloud import bigquery, storage, dlp_v2, kms_v1\n",
        "    from google.cloud import logging as cloud_logging\n",
        "    from google.oauth2 import service_account\n",
        "    from google.api_core.exceptions import GoogleAPICallError\n",
        "    HAS_GOOGLE_DEPS = True\n",
        "except ImportError:\n",
        "    HAS_GOOGLE_DEPS = False\n",
        "    print(\"Google Cloud client libraries not available. Running in simulation mode.\")\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class GovernanceDomain(Enum):\n",
        "    DATA_SECURITY = \"Data Security & Encryption\"\n",
        "    MODEL_PRIVACY = \"Model Privacy & Safe Inference\"\n",
        "    MONITORING = \"Monitoring & Auditing\"\n",
        "    ACCESS_CONTROL = \"Access Controls\"\n",
        "    DATA_RESIDENCY = \"Data Residency & Retention\"\n",
        "    DEPLOYMENT = \"CI/CD & Deployment Controls\"\n",
        "\n",
        "class GoogleCloudDataGovernance:\n",
        "    \"\"\"Implementation of data governance controls using Google Cloud services\"\"\"\n",
        "\n",
        "    def __init__(self, project_id: str, location: str = \"us-central1\"):\n",
        "        self.project_id = project_id\n",
        "        self.location = location\n",
        "        self.setup_clients()\n",
        "\n",
        "    def setup_clients(self):\n",
        "        \"\"\"Initialize Google Cloud clients\"\"\"\n",
        "        if not HAS_GOOGLE_DEPS:\n",
        "            self.simulation_mode = True\n",
        "            logger.warning(\"Running in simulation mode - no actual GCP calls will be made\")\n",
        "            return\n",
        "\n",
        "        self.simulation_mode = False\n",
        "\n",
        "        try:\n",
        "            # Initialize clients with default credentials\n",
        "            self.bq_client = bigquery.Client(project=self.project_id)\n",
        "            self.storage_client = storage.Client(project=self.project_id)\n",
        "            self.dlp_client = dlp_v2.DlpServiceClient()\n",
        "            self.kms_client = kms_v1.KeyManagementServiceClient()\n",
        "            self.logging_client = cloud_logging.Client(project=self.project_id)\n",
        "\n",
        "            logger.info(\"Google Cloud clients initialized successfully\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to initialize GCP clients: {e}\")\n",
        "            self.simulation_mode = True\n",
        "\n",
        "    # 1. Data Security & Encryption Methods\n",
        "    def create_encrypted_bigquery_table(self, dataset_id: str, table_id: str, kms_key_name: str) -> bool:\n",
        "        \"\"\"Create a BigQuery table encrypted with CMEK\"\"\"\n",
        "        if self.simulation_mode:\n",
        "            logger.info(f\"SIMULATION: Created BigQuery table {dataset_id}.{table_id} encrypted with KMS key {kms_key_name}\")\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            # Create dataset if it doesn't exist\n",
        "            dataset_ref = bigquery.DatasetReference(self.project_id, dataset_id)\n",
        "            dataset = bigquery.Dataset(dataset_ref)\n",
        "            dataset.location = self.location\n",
        "            dataset = self.bq_client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "            # Create table with encryption specification\n",
        "            schema = [\n",
        "                bigquery.SchemaField(\"user_id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "                bigquery.SchemaField(\"sensitive_data\", \"STRING\", mode=\"NULLABLE\"),\n",
        "                bigquery.SchemaField(\"timestamp\", \"TIMESTAMP\", mode=\"REQUIRED\"),\n",
        "            ]\n",
        "\n",
        "            table_ref = dataset.table(table_id)\n",
        "            table = bigquery.Table(table_ref, schema=schema)\n",
        "            table.encryption_configuration = bigquery.EncryptionConfiguration(\n",
        "                kms_key_name=kms_key_name\n",
        "            )\n",
        "\n",
        "            table = self.bq_client.create_table(table)\n",
        "            logger.info(f\"Created encrypted BigQuery table {table.project}.{table.dataset_id}.{table.table_id}\")\n",
        "            return True\n",
        "\n",
        "        except GoogleAPICallError as e:\n",
        "            logger.error(f\"Failed to create encrypted BigQuery table: {e}\")\n",
        "            return False\n",
        "\n",
        "    def create_encrypted_storage_bucket(self, bucket_name: str, kms_key_name: str) -> bool:\n",
        "        \"\"\"Create a Cloud Storage bucket encrypted with CMEK\"\"\"\n",
        "        if self.simulation_mode:\n",
        "            logger.info(f\"SIMULATION: Created Cloud Storage bucket {bucket_name} encrypted with KMS key {kms_key_name}\")\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            bucket = self.storage_client.bucket(bucket_name)\n",
        "            bucket.storage_class = \"STANDARD\"\n",
        "            bucket.location = self.location\n",
        "            bucket.encryption_configuration = storage.BucketEncryptionConfig(\n",
        "                default_kms_key_name=kms_key_name\n",
        "            )\n",
        "\n",
        "            bucket = self.storage_client.create_bucket(bucket)\n",
        "            logger.info(f\"Created encrypted Cloud Storage bucket {bucket.name}\")\n",
        "            return True\n",
        "\n",
        "        except GoogleAPICallError as e:\n",
        "            logger.error(f\"Failed to create encrypted storage bucket: {e}\")\n",
        "            return False\n",
        "\n",
        "    # 2. Model Privacy and Safe Inference Methods\n",
        "    def scan_for_pii(self, content: str, info_types: List[str] = None) -> Dict:\n",
        "        \"\"\"Scan content for PII using Cloud DLP API\"\"\"\n",
        "        if info_types is None:\n",
        "            info_types = [\"EMAIL_ADDRESS\", \"PHONE_NUMBER\", \"US_SOCIAL_SECURITY_NUMBER\"]\n",
        "\n",
        "        if self.simulation_mode:\n",
        "            # Simulate DLP scanning\n",
        "            findings = []\n",
        "            if \"@\" in content:\n",
        "                findings.append({\"info_type\": \"EMAIL_ADDRESS\", \"likelihood\": \"LIKELY\"})\n",
        "            if any(char.isdigit() for char in content) and len(content) > 10:\n",
        "                findings.append({\"info_type\": \"PHONE_NUMBER\", \"likelihood\": \"POSSIBLE\"})\n",
        "\n",
        "            return {\"findings\": findings, \"content\": content}\n",
        "\n",
        "        try:\n",
        "            # Prepare DLP request\n",
        "            parent = f\"projects/{self.project_id}\"\n",
        "\n",
        "            # Construct inspect config\n",
        "            inspect_config = {\n",
        "                \"info_types\": [{\"name\": it} for it in info_types],\n",
        "                \"min_likelihood\": dlp_v2.Likelihood.POSSIBLE,\n",
        "                \"limits\": {\"max_findings_per_request\": 100},\n",
        "            }\n",
        "\n",
        "            # Construct item to inspect\n",
        "            item = {\"value\": content}\n",
        "\n",
        "            # Call DLP API\n",
        "            response = self.dlp_client.inspect_content(\n",
        "                request={\n",
        "                    \"parent\": parent,\n",
        "                    \"inspect_config\": inspect_config,\n",
        "                    \"item\": item,\n",
        "                }\n",
        "            )\n",
        "\n",
        "            # Process results\n",
        "            findings = []\n",
        "            for finding in response.result.findings:\n",
        "                findings.append({\n",
        "                    \"info_type\": finding.info_type.name,\n",
        "                    \"likelihood\": finding.likelihood.name,\n",
        "                    \"quote\": finding.quote,\n",
        "                })\n",
        "\n",
        "            return {\"findings\": findings, \"content\": content}\n",
        "\n",
        "        except GoogleAPICallError as e:\n",
        "            logger.error(f\"DLP API error: {e}\")\n",
        "            return {\"findings\": [], \"content\": content, \"error\": str(e)}\n",
        "\n",
        "    def deidentify_with_masking(self, content: str, info_types: List[str] = None) -> Dict:\n",
        "        \"\"\"De-identify content by masking PII\"\"\"\n",
        "        if info_types is None:\n",
        "            info_types = [\"EMAIL_ADDRESS\", \"PHONE_NUMBER\", \"US_SOCIAL_SECURITY_NUMBER\"]\n",
        "\n",
        "        if self.simulation_mode:\n",
        "            # Simple simulation of masking\n",
        "            masked_content = content\n",
        "            if \"@\" in content:\n",
        "                # Mask email\n",
        "                parts = content.split(\"@\")\n",
        "                if len(parts) > 1:\n",
        "                    masked_content = masked_content.replace(parts[0], \"***\")\n",
        "            # Add more simulation logic for other PII types\n",
        "            return {\"original\": content, \"masked\": masked_content}\n",
        "\n",
        "        try:\n",
        "            parent = f\"projects/{self.project_id}\"\n",
        "\n",
        "            # Deidentify config - use masking transformation\n",
        "            deidentify_config = {\n",
        "                \"info_type_transformations\": {\n",
        "                    \"transformations\": [\n",
        "                        {\n",
        "                            \"primitive_transformation\": {\n",
        "                                \"character_mask_config\": {\n",
        "                                    \"masking_character\": \"#\",\n",
        "                                    \"number_to_mask\": 0,  # Mask all found\n",
        "                                    \"reverse_order\": False,\n",
        "                                }\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Inspect config to identify what to de-identify\n",
        "            inspect_config = {\n",
        "                \"info_types\": [{\"name\": it} for it in info_types]\n",
        "            }\n",
        "\n",
        "            item = {\"value\": content}\n",
        "\n",
        "            # Call DLP API for de-identification\n",
        "            response = self.dlp_client.deidentify_content(\n",
        "                request={\n",
        "                    \"parent\": parent,\n",
        "                    \"deidentify_config\": deidentify_config,\n",
        "                    \"inspect_config\": inspect_config,\n",
        "                    \"item\": item,\n",
        "                }\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                \"original\": content,\n",
        "                \"masked\": response.item.value,\n",
        "                \"transformations_applied\": len(response.overview.transformation_summaries)\n",
        "            }\n",
        "\n",
        "        except GoogleAPICallError as e:\n",
        "            logger.error(f\"DLP de-identification error: {e}\")\n",
        "            return {\"original\": content, \"masked\": content, \"error\": str(e)}\n",
        "\n",
        "    def apply_content_guardrails(self, prompt: str, blocked_phrases: List[str] = None) -> Dict:\n",
        "        \"\"\"Apply content safety guardrails (simulating Vertex AI Guardrails)\"\"\"\n",
        "        if blocked_phrases is None:\n",
        "            blocked_phrases = [\"confidential\", \"sensitive\", \"password\", \"ssn\", \"credit card\"]\n",
        "\n",
        "        # Check for blocked phrases\n",
        "        found_phrases = []\n",
        "        for phrase in blocked_phrases:\n",
        "            if phrase.lower() in prompt.lower():\n",
        "                found_phrases.append(phrase)\n",
        "\n",
        "        # Calculate safety score\n",
        "        safety_score = 1.0  # Start with perfect score\n",
        "        if found_phrases:\n",
        "            safety_score = max(0.1, 1.0 - (len(found_phrases) * 0.3))\n",
        "\n",
        "        return {\n",
        "            \"is_safe\": safety_score > 0.5,\n",
        "            \"safety_score\": safety_score,\n",
        "            \"blocked_phrases_found\": found_phrases,\n",
        "            \"recommendation\": \"Proceed\" if safety_score > 0.5 else \"Block this content\"\n",
        "        }\n",
        "\n",
        "    # 3. Monitoring, Auditing, and Compliance Methods\n",
        "    def log_governance_event(self, event_type: str, resource: str, details: Dict) -> bool:\n",
        "        \"\"\"Log governance event to Cloud Logging\"\"\"\n",
        "        log_data = {\n",
        "            \"event_type\": event_type,\n",
        "            \"resource\": resource,\n",
        "            \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
        "            \"details\": details,\n",
        "            \"operation\": {\n",
        "                \"project\": self.project_id,\n",
        "                \"location\": self.location\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if self.simulation_mode:\n",
        "            logger.info(f\"SIMULATION: Logging governance event - {event_type}: {json.dumps(log_data)}\")\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            logger = self.logging_client.logger(\"data-governance-logs\")\n",
        "            logger.log_struct(log_data, severity=\"INFO\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to log governance event: {e}\")\n",
        "            return False\n",
        "\n",
        "    def generate_compliance_report(self, timeframe_days: int = 30) -> Dict:\n",
        "        \"\"\"Generate a compliance report (simulated)\"\"\"\n",
        "        end_time = datetime.utcnow()\n",
        "        start_time = end_time - timedelta(days=timeframe_days)\n",
        "\n",
        "        # This would typically query Cloud Logging or Monitoring API\n",
        "        return {\n",
        "            \"timeframe\": {\n",
        "                \"start\": start_time.isoformat(),\n",
        "                \"end\": end_time.isoformat()\n",
        "            },\n",
        "            \"summary\": {\n",
        "                \"total_events\": 1500,\n",
        "                \"pii_detections\": 42,\n",
        "                \"blocked_attempts\": 7,\n",
        "                \"encryption_operations\": 893\n",
        "            },\n",
        "            \"compliance_status\": {\n",
        "                \"GDPR\": \"COMPLIANT\",\n",
        "                \"HIPAA\": \"COMPLIANT\",\n",
        "                \"PCI_DSS\": \"COMPLIANT\",\n",
        "                \"CCPA\": \"COMPLIANT\"\n",
        "            },\n",
        "            \"recommendations\": [\n",
        "                \"Review access patterns for encrypted BigQuery tables\",\n",
        "                \"Consider adding additional blocked phrases to guardrails\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    # 4. Access Controls Methods\n",
        "    def check_access_permissions(self, user: str, resource: str, permission: str) -> Dict:\n",
        "        \"\"\"Check if a user has access to a resource (simulated)\"\"\"\n",
        "        # In a real implementation, this would use IAM Policy Simulator API\n",
        "        access_rules = {\n",
        "            \"data-scientist@example.com\": {\n",
        "                \"bigquery.datasets\": [\"read\", \"query\"],\n",
        "                \"storage.buckets\": [\"read\"]\n",
        "            },\n",
        "            \"ml-engineer@example.com\": {\n",
        "                \"bigquery.datasets\": [\"read\", \"query\", \"write\"],\n",
        "                \"storage.buckets\": [\"read\", \"write\"],\n",
        "                \"vertexai.models\": [\"read\", \"deploy\"]\n",
        "            },\n",
        "            \"admin@example.com\": {\n",
        "                \"*\": [\"*\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        user_permissions = access_rules.get(user, {})\n",
        "        resource_type = resource.split(\"/\")[0] if \"/\" in resource else resource\n",
        "\n",
        "        # Check if user has wildcard access\n",
        "        if \"*\" in user_permissions and \"*\" in user_permissions[\"*\"]:\n",
        "            return {\"has_access\": True, \"reason\": \"Admin privileges\"}\n",
        "\n",
        "        # Check resource-specific permissions\n",
        "        if resource_type in user_permissions:\n",
        "            if permission in user_permissions[resource_type] or \"*\" in user_permissions[resource_type]:\n",
        "                return {\"has_access\": True, \"reason\": f\"Has {permission} permission on {resource_type}\"}\n",
        "\n",
        "        return {\"has_access\": False, \"reason\": \"No matching permissions found\"}\n",
        "\n",
        "    # 5. Data Residency & Retention Methods\n",
        "    def set_data_retention_policy(self, bucket_name: str, retention_days: int) -> bool:\n",
        "        \"\"\"Set data retention policy on a Cloud Storage bucket\"\"\"\n",
        "        if self.simulation_mode:\n",
        "            logger.info(f\"SIMULATION: Set retention policy of {retention_days} days on bucket {bucket_name}\")\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            bucket = self.storage_client.get_bucket(bucket_name)\n",
        "            bucket.retention_policy = retention_days * 86400  # Convert days to seconds\n",
        "            bucket.patch()\n",
        "            logger.info(f\"Set retention policy of {retention_days} days on bucket {bucket_name}\")\n",
        "            return True\n",
        "        except GoogleAPICallError as e:\n",
        "            logger.error(f\"Failed to set retention policy: {e}\")\n",
        "            return False\n",
        "\n",
        "    def enforce_data_location(self, dataset_id: str, location: str) -> bool:\n",
        "        \"\"\"Enforce data location for BigQuery dataset\"\"\"\n",
        "        if self.simulation_mode:\n",
        "            logger.info(f\"SIMULATION: Enforced data location {location} for dataset {dataset_id}\")\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            dataset_ref = bigquery.DatasetReference(self.project_id, dataset_id)\n",
        "            dataset = self.bq_client.get_dataset(dataset_ref)\n",
        "\n",
        "            if dataset.location != location:\n",
        "                logger.warning(f\"Dataset location ({dataset.location}) doesn't match required location ({location})\")\n",
        "                return False\n",
        "\n",
        "            logger.info(f\"Dataset {dataset_id} location verified: {location}\")\n",
        "            return True\n",
        "        except GoogleAPICallError as e:\n",
        "            logger.error(f\"Failed to verify dataset location: {e}\")\n",
        "            return False\n",
        "\n",
        "def main():\n",
        "    \"\"\"Demonstrate comprehensive data governance implementation\"\"\"\n",
        "    print(\"üîê Google Cloud Data Governance for GenAI Solutions\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Initialize governance framework\n",
        "    project_id = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"my-genai-project\")\n",
        "    governance = GoogleCloudDataGovernance(project_id)\n",
        "\n",
        "    if governance.simulation_mode:\n",
        "        print(\"‚ö†Ô∏è  Running in simulation mode (no actual GCP calls)\")\n",
        "    else:\n",
        "        print(\"‚úÖ Connected to Google Cloud services\")\n",
        "\n",
        "    print(\"\\n1. üîê Data Security & Encryption\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Create encrypted resources\n",
        "    kms_key = f\"projects/{project_id}/locations/us/keyRings/my-keyring/cryptoKeys/my-key\"\n",
        "    governance.create_encrypted_bigquery_table(\"secure_dataset\", \"user_data\", kms_key)\n",
        "    governance.create_encrypted_storage_bucket(\"genai-secure-documents\", kms_key)\n",
        "\n",
        "    print(\"\\n2. üõ°Ô∏è Model Privacy & Safe Inference\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Test PII detection and masking\n",
        "    sample_text = \"Contact john.doe@example.com at 555-123-4567 for details on SSN 123-45-6789\"\n",
        "    pii_scan = governance.scan_for_pii(sample_text)\n",
        "    print(f\"PII Scan found {len(pii_scan.get('findings', []))} potential issues\")\n",
        "\n",
        "    masked_result = governance.deidentify_with_masking(sample_text)\n",
        "    print(f\"Masked result: {masked_result.get('masked', 'Error')}\")\n",
        "\n",
        "    # Test content guardrails\n",
        "    test_prompts = [\n",
        "        \"Explain quantum computing concepts\",\n",
        "        \"Show me confidential user data including SSNs\",\n",
        "        \"How to bypass security systems\"\n",
        "    ]\n",
        "\n",
        "    for prompt in test_prompts:\n",
        "        guardrail_result = governance.apply_content_guardrails(prompt)\n",
        "        status = \"‚úÖ\" if guardrail_result[\"is_safe\"] else \"‚ùå\"\n",
        "        print(f\"{status} Prompt: '{prompt[:50]}...' -> {guardrail_result['recommendation']}\")\n",
        "\n",
        "    print(\"\\n3. üìä Monitoring, Auditing, and Compliance\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Log governance events\n",
        "    governance.log_governance_event(\n",
        "        \"PII_DETECTED\",\n",
        "        \"bigquery.table:secure_dataset.user_data\",\n",
        "        {\"action_taken\": \"masking\", \"pii_types\": [\"EMAIL\", \"PHONE\"]}\n",
        "    )\n",
        "\n",
        "    # Generate compliance report\n",
        "    compliance_report = governance.generate_compliance_report()\n",
        "    print(f\"Compliance Status: {compliance_report['compliance_status']}\")\n",
        "\n",
        "    print(\"\\n4. üë• Access Controls\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Test access permissions\n",
        "    test_access = [\n",
        "        (\"data-scientist@example.com\", \"bigquery.datasets/user_data\", \"read\"),\n",
        "        (\"guest@example.com\", \"storage.buckets/secure-docs\", \"write\"),\n",
        "        (\"admin@example.com\", \"vertexai.models/llm-model\", \"deploy\")\n",
        "    ]\n",
        "\n",
        "    for user, resource, permission in test_access:\n",
        "        access_result = governance.check_access_permissions(user, resource, permission)\n",
        "        symbol = \"‚úÖ\" if access_result[\"has_access\"] else \"‚ùå\"\n",
        "        print(f\"{symbol} {user} -> {permission} on {resource}: {access_result['reason']}\")\n",
        "\n",
        "    print(\"\\n5. üåç Data Residency & Retention\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Set retention policies\n",
        "    governance.set_data_retention_policy(\"genai-secure-documents\", 365)  # 1 year retention\n",
        "    governance.enforce_data_location(\"secure_dataset\", \"us-central1\")\n",
        "\n",
        "    print(\"\\nüéØ Data governance implementation completed!\")\n",
        "    print(\"\\nSummary of GCP services utilized:\")\n",
        "    print(\"‚Ä¢ BigQuery with CMEK for encrypted structured data\")\n",
        "    print(\"‚Ä¢ Cloud Storage with CMEK for encrypted unstructured data\")\n",
        "    print(\"‚Ä¢ Cloud DLP for PII detection and masking\")\n",
        "    print(\"‚Ä¢ Cloud KMS for encryption key management\")\n",
        "    print(\"‚Ä¢ Cloud Logging for audit trails\")\n",
        "    print(\"‚Ä¢ IAM for access controls\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}